---
title: notes
author: Alexander Senetcky
format:
    html:
        embed-resources: true
---

```{python}
# | label: setup
# | code-fold: true

import tensorflow_data_validation as tfdv
import polars as pl
```

grabbed some spam data and moved to `data/spam.csv`.

```{python}
# | label: example
stats = pl.read_csv("data/spam.csv", encoding="latin-1").to_pandas()
stats = tfdv.generate_statistics_from_dataframe(stats)

print(stats.datasets[0].features[0].string_stats.rank_histogram)

tfdv.visualize_statistics(stats)
```

whoa - ^ that actually renders out with quarto to html.
I wasn't sure if it would. perhaps not the best medium, but for
something quick - that's amazing.

## Overview

Just jotting down notes. Trying to take advantage of repitition.
Going through the book Machine Learning Production Systems.

## quick intro example

## Preprocessing

- data wrangling and data cleansing
    - enforcing correct data types
    - valid values
    - eliminating or correcting erroneous data
    - per-feature tranformations
- Normalizing and standardizing
    - normalizing: aka min-max scaling, shifts and scales features 
    to value range of [0,1]
    -standardization aka z-score shifts and scales features to 
    values of mean 0 and standard deviation of 1.
    - both require _global_ attributes known for your feature values
    aka you need to know min and max.
        - this can be signifcant processing for large datasets.
    - when to pick which one?
        - you can experiment and see which works better 
        - OR if values seem to be a gaussian dist - standardization 
        probably a better choice - otherwise normalization is the 
        way to go.
- Bucketizing
    - create categories based on a numeric range - think quantile bucketing
    - feature crosses - combine multi feats into a new feat. encode nonlinearity
    in a feature space or encode the same info with fewer features.
    - e.g we have 2 feats- day of week and hour of day -> sqeeze into hour of 
    week and get two for one.
- One-hot encoding
- Dimensionality reduction
    - reduce the number of input features while retaining the
    greatest variance
    - PCA - the most widely known dimentionality reduction algo
    project your data into a lower dimensional space
    - t-distributed stochastic neighbor embedding (t-SNE) and
    Uniform Manifold Approximation and Projection (UMAP) do this as well.
    -  can be visual but _usually_  __semantic__ or __word__ embeddings.
    - e.g. the word _apple_ will be much closer in meaning to the word
    _orange_ but further from _sailboat_.
    - data is projected into a semantic embedding space by training a model
    to understand the relationships between items - often through
    self-supervised trainings on very large datasets or _corpora_.
- Image Transformations
    
    
## feature transformation at scale
- folks used to hop across different envs -  now there are _unified_ frameworks
called _pipelines_ to train and deploy with _consistent_ and _reproducible_
results.

### choose a framework that scales well

- pandas does not scale
- apache beam can run on the laptop - direct runner
- then can be swapped for google dataflow runner or apache flink runner

### avoid training-serving skew

- consistnecy!!
- what you do to training you should do to serving.
- old days - dev/train in python and then switch to java - rife with issues

### consider instance-level full-pass transformations

- __instance-level transformations__: take an example and transfrom separately
without refencing anything else
- __full-pass transformations__: need to analyze the entire dataset before doing
any transformations.

- normalization - that's _full-pass_ - possibly not feasible on TBs of data
-  determining buckets - could be _full-pass_, not always though.


## using TensorFlow Transfrom

need good tools to do feature engineering at scale.

TensorFlow Transfrom (TFT) is a separate open source library
that can be used by iteself - in the book they are going to use it in
the context of TensorFlow Extended pipelines (TFX).

::: {.callout-note}
    Think of TFX pipelines as a complete training process
    designed to be used for production deployments.
:::

TFT can be used for __processing__, __training__, and __serving__
requests, especially if using TF. if not working in TF you can still
use TFT - but serving will need to be done elsewhere.

by combining both - transformations done are included in the model
so the same transforms are done regardless of where you _deploy_. neat!

### typical TFX pipeline

1. raw data to ExampleGen
    1. ExampleGen ingest sand splits data into training and eval by default 
1. then to StatisticsGen
    1. StatisticsGen calcs stats, full pass over mean, sd min, mac etc...
1. then on to SchemaGen

```{mermaid}
flowchart LR
A[raw data] --> B[ExampleGen]
B --> C[StatisticsGen]
C --> D[SchemaGen]
D --> E(Downstream)
E --> F[ExampleValidator]
```

etc....


## Analyzers

In order to do simple calcs or impressive calcs over gobs
of data TF has the concept _analyzers_.

examples:

- scaling
    - scale_to_z_score
    - scale_to_0_1
- bucketizing
    - quantiles
    - apply_buckets
    - bucketize
- vocabulary
    - bag_of_words
    -tfidf
    -ngrams
- dimentionality reduction
    - pca

analyzers use apache beam for processing. they only run once
for each model training workflow and _not_ during serving.
instead the results produced are captured as _constants_ in
the transform graph and included in a saved model.
constants are then used as part of transforming individual examples
during training and serving.

### Code example


```{python}
# | eval: false

import tensorflow_transform as tft


def preprocessing_fn(inputs):
    # feature engineering code

    # for example
    for key in DENSE_FLOAT_FEATURE_KEYS:
        outputs[key] = tft.scale_to_z_Score(inputs[key])

    for key in VOCAB_FEATURE_KEYS:
        outputs[key] = tft.vocabulary(inputs[key], vocab_filename=key)

    for key in BUCKET_FEATURE_KEYS:
        outputs[key] = tft.bucketize(inputs[key], FEATURE_BUCKET_COUNT)

```

## Feature Selection

_feature selection_ is a set of algos and techniques designed to
improve qualirt of data by determining which features actually help
your model learn.

### feature spaces
- feature space: n-dimentional space defined by features, minus your target
label. so 2 features, 2 dimensional, 3, 3 dimensional etc...

- features space coverage
    - think - almost like code coverage
    - you have your training feature space coverage
    - and your serving feature space + coverage
    - ideally they are the same, and/or trianing is slightly larger
    - keep monitoring in place to watch drift if ranges shift

goal of feature selection: include only minimum number of features
that provide the maximum amount of predictive information
to help our model learn.


resource considerations for having each feature

^ feature  ^ cost + complexity

- unsupervised feature selection
    - no consideration between feature and label
    - looks at how _correlated_ features are to each other
    - if two or more featurew are highly corellated - consider
    keeping only, the best performing one

- supervised feature selection
    - focuses on relationship between feature and label
    - tries to assess predictive info associated with each feature
    called __feature importance__

### filter methods
use correlation to filter features

- pearson
- kendall tau
- spearman

f-test, mutual information, chi-squared


```{python}
# | label: pandas-example
# | eval: false

# pearson correlation is default in pandas
cor = df.corr()
cor_target = abs(cor["feature_name"])

# select highly correlated features to reduce/ elim
redundant_features = cor_target[cor_target > 0.8]
```

lets look at univariate feature selection with `scikit-learn`.


```{python}
# | eval: false

# typical scikit-learn pattern per author

import sklearn


def univariate_selection():
    X_train, X_test, Y_train, Y_test = train_test_split(
        X, Y, test_size=0.2, stratify=Y, random_state=123
    )

    X_train_scaled = StandardScaler().fit_transform(X_train)
    X_test_scaled = StandardScaler().fit_transform(X_test)
    min_max_scaler = MinMaxScaler()
    Scaled_X = min_max_scaler.fit_transform(X_train_scaled)
    selector = SelectKBest(chi2, k=20)  # use chi-squared test
    X_new = selector.fit_transform(Scaled_x, Y_train)
    feeature_idx = selector.get_support()
    feature_names = df.drop("diagnosis_int", axis=1).columns[feature_idx]  # pandas
    return feature_names
```

### wrapper methods

- supervised - meaning they ened labels
- measure impact of iteratively adding/ dropping features

- choose feature per iter
- train and eval
- compare eval metrics

computationally demaining.


three types of wrapper methods
- forward selection: 
    - iterative and greedy
    - start with 1 feat, train and eval
    - next iter, keep prev feat and add one additional feat, repeat
    - keep features that goive best performance for the enxt round
    - repeat until no improvement
- backward elimination:
    - basically the opposite of forward selection
    - start with all features and then remove them one by one

- recursive feature elimination:
    - use _feature importance_ NOT model performance.
    - select number of desired features you want
    - then start with all features, train model, remove a feature, train model
    repeat....
    - rank features by feature important (need to have a method for assign importance)
    - discard features to get down to desired number


not all models can measure importance. the most cmmon class of models
that offer the ability to measure importance is tree-based models.
Also, you need to decide how many features you want, and that
isn't always obvious.


recursive feature elimination with scikit learn might
look like this:

```{python}
# | eval: false


def run_rfe(label_name, X, Y, num_to_keep):
    X_train, X_test, y_train, y_test = train_test_split(
        X, Y, test_size=0.2, random_state=0
    )
    
    X_train_scaled = StandardScaler().fit_transform(X_train)
    X_test_scaled = StandardScaler().fit_transform(X_test)

    model = RandomForestClassifier(
        criterion = "entropy",
        random_State = 47
    )
    
    rfe = RFE(model, n_features_to_select = num_to_keep)
    rfe = rfe.fit(X_train_scaled, y_train)
    
    feature_names = df.drop(label_name, axis = 1).columns(rfe.get_suppport())

    return feature_names

```

### embedded methods

etc...

### using TF transform to tokenize text

a BERT model will want tokens and token ids.
they might also expect _control tokens_ such as
start, stop or pad tokens.

Tensorflow Text for this example - also PyTorch's TorchText.

Before converting text into tokens
you should normalize  the text to supported char encoding (utf-8)
and clean (remove common patterns that occur in every sample)


> which tokenizer should you use?
> the type of tokenizer should match
> what was used by the foundational model
> in this example BERT.


BERT example


```{python}
# | eval: false

import tensorflow as tf
import tensorflow_hub as hub
import tensorflow_text as tf_text

START_TOKEN_ID = 101
END_TOKEN__ID = 102

TFHUB_URL = (
    "https://www.kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-preprocess/3"
)


def load_bert_model(model_url=TFHUB_URL):
    bert_layer = hub.KerasLayer(handle=model_url, trainable=False)
    return bert_layer


def _preprocessing_fn(inputs):
    vocab_file_path = (
        load_bert_model().resolved_object.vocab_file.asset_path
    )  # I can't get vocab_file onward to work (dunno if this is outdated?)

    bert_tokenizer = tf_text.BertTokenizer(
        vocab_lookup_table=vocab_file_path, token_out_type=tf.int64, lower_case=True
    )

    text = inputs["message"]
    category = inputs["category"]

    # normalize text
    text = tf_text.normalize_utf8(text)

    # tokenization
    tokens = bert_tokenizer.tokenize(text).merge_dims(1, -1)

    # add control tokens
    tokens, input_type_ids = tf_text.combine_segments(
        tokens, start_of_sequence_id=START_TOKEN_ID, end_of_segment_id=END_TOKEN__ID
    )

    # token truncation / padding
    tokens, input_mask_ids = tf_text.pad_model_inputs(tokens, max_seq_length=128)

    # convert categories to labels
    labels = tft.compute_and_apply_vocabulary(label, vocab_filename="category")

    return {
        "labels": labels,
        "input_ids": tokens,
        "input_mask_ids": input_mask_ids,
        "input_type_ids": input_type_ids,
    }
```
